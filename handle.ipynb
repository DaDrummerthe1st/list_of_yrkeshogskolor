{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all I have to import and handle the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "html_file_path = 'hitta_utbildning.html' # 1218 courses\n",
    "\n",
    "with open(html_file_path) as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "articles = soup.body.find_all('article')\n",
    "dl = soup.body.find_all('dl')\n",
    "\n",
    "def find_school(course_name):\n",
    "    pass\n",
    "\n",
    "data = []\n",
    "for index, h in enumerate(soup.body.find_all('article')[1:]):\n",
    "    course_name = h.find(class_ = \"h-byline\").text\n",
    "    course_start = h.find_all('dd')[0].text\n",
    "    course_length = h.find_all('dd')[1].text\n",
    "    course_percentage = h.find_all('dd')[2].text\n",
    "    course_city = h.find_all('dd')[3].text\n",
    "    school_name = h.find_all('dd')[4].text\n",
    "\n",
    "    data.append(dict(course_index = index+1, \n",
    "                    course = course_name,\n",
    "                    school = school_name,\n",
    "                    start = course_start,\n",
    "                    length = course_length,\n",
    "                    percentage = course_percentage,\n",
    "                    city = course_city\n",
    "                    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'course_index': 6, 'course': '3D-printingspecialist', 'school': 'Resurs Applikation Process System i Skåne AB', 'start': 'September 2025', 'length': '200 YH-poäng (ca 1,5 år)', 'percentage': '75%', 'city': 'Distans (Halmstad)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "school\n",
       "TUC Sweden AB - Yrkeshögskola                           True\n",
       "YH Akademin AB                                          True\n",
       "Göteborgs Stad, Yrgo                                    True\n",
       "Lernia Utbildning AB                                    True\n",
       "Plushögskolan AB - Teknikhögskolan                      True\n",
       "                                                       ...  \n",
       "Institutet för Högre Urmakeriutbildning i Norden AB    False\n",
       "Campus Åre/Åre kommun                                  False\n",
       "Vilhelmina kommun, Vilhelmina Lärcentrum               False\n",
       "Movant AB                                              False\n",
       "Markaryds kommun, Lärcentrum Markaryd                  False\n",
       "Name: count, Length: 250, dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(data[5])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df['school'].unique().size)\n",
    "display(df['school'].value_counts() > 5)\n",
    "# print(dl)\n",
    "# print(articles)\n",
    "# df.append(data)\n",
    "\n",
    "# display(df)\n",
    "\n",
    "\n",
    "# articles = list(soup.body.find_all('article')[1:])\n",
    "# print(articles.class)\n",
    "# df = pd.DataFrame(articles)\n",
    "# articles_json = json.load(articles)\n",
    "# print(articles_json)\n",
    "\n",
    "# df = pd.DataFrame(articles[1:])\n",
    "# display(df)\n",
    "\n",
    "# print(articles)\n",
    "# for headline in articles.find_all(class_ = \"h-byline\"):\n",
    "#     print(headline)\n",
    "\n",
    "# for article in articles[1:]:\n",
    "#     for headline in \n",
    "\n",
    "# print(len(articles))\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(headlines)\n",
    "# display(df)\n",
    "\n",
    "#print(len(headlines)) # 1218!\n",
    "\n",
    "#print(headlines.get_text())\n",
    "\n",
    "# def read_html_with_beautiful_soup(file_path):\n",
    "#     # Read HTML file\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         # Parse HTML using BeautifulSoup\n",
    "#         soup = BeautifulSoup(f, 'html.parser')\n",
    "#     # Find all tables in the HTML\n",
    "#     tables = soup.find_all('table')\n",
    "#     # Read tables into DataFrame using read_html()\n",
    "#     df = pd.read_html(str(tables))[0]\n",
    "#     return df\n",
    "\n",
    "# # Read HTML file using BeautifulSoup with read_html()\n",
    "# df = read_html_with_beautiful_soup(html_file_path)\n",
    "\n",
    "# # Display DataFrame\n",
    "# print(\"Approach 2 Output:\")\n",
    "# display(df.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
