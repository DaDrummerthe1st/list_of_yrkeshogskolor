{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all I have to import and handle the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m articles = \u001b[38;5;28mlist\u001b[39m(soup.body.find_all(\u001b[33m'\u001b[39m\u001b[33marticle\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m1\u001b[39m:])\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# print(articles)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m articles_json = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m display(articles_json)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# df = pd.DataFrame(articles[1:])\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# display(df)\u001b[39;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# print(\"Approach 2 Output:\")\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# display(df.head())\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m         \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m         parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "html_file_path = 'hitta_utbildning.html' # 1218 courses\n",
    "\n",
    "with open(html_file_path) as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "articles = list(soup.body.find_all('article')[1:])\n",
    "# print(articles)\n",
    "articles_json = json.load(articles)\n",
    "display(articles_json)\n",
    "\n",
    "# df = pd.DataFrame(articles[1:])\n",
    "# display(df)\n",
    "\n",
    "# print(articles)\n",
    "# for headline in articles.find_all(class_ = \"h-byline\"):\n",
    "#     print(headline)\n",
    "\n",
    "# for article in articles[1:]:\n",
    "#     for headline in \n",
    "\n",
    "# print(len(articles))\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(headlines)\n",
    "# display(df)\n",
    "\n",
    "#print(len(headlines)) # 1218!\n",
    "\n",
    "#print(headlines.get_text())\n",
    "\n",
    "# def read_html_with_beautiful_soup(file_path):\n",
    "#     # Read HTML file\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         # Parse HTML using BeautifulSoup\n",
    "#         soup = BeautifulSoup(f, 'html.parser')\n",
    "#     # Find all tables in the HTML\n",
    "#     tables = soup.find_all('table')\n",
    "#     # Read tables into DataFrame using read_html()\n",
    "#     df = pd.read_html(str(tables))[0]\n",
    "#     return df\n",
    "\n",
    "# # Read HTML file using BeautifulSoup with read_html()\n",
    "# df = read_html_with_beautiful_soup(html_file_path)\n",
    "\n",
    "# # Display DataFrame\n",
    "# print(\"Approach 2 Output:\")\n",
    "# display(df.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
